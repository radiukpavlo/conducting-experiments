{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c516556-8e84-4583-acb9-fbcf2cafeeeb",
   "metadata": {
    "id": "N8LsPXZti9Sw",
    "tags": []
   },
   "source": [
    "<h1><center>Laboratory work 2.</center></h1>\n",
    "<h2><center>PyTorch Workflow Exercise</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb97ff57-7b9a-4675-9b32-453f56a4dbd4",
   "metadata": {},
   "source": [
    "**Виконав:** Last name and First name\n",
    "\n",
    "**Варіант:** #__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b78c9c-bf57-4d9d-81b9-0737e07a8e32",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22795d29-bb8e-4394-adc6-e7f1a489a2d5",
   "metadata": {},
   "source": [
    "## Content\n",
    "\n",
    "1. [Create a straight line dataset](#1.1)\n",
    "2. [Build a PyTorch model](#1.2)\n",
    "3. [Create a loss function and an optimizer](#1.3)\n",
    "4. [Make predictions with the trained model on the test data](#1.4)\n",
    "5. [Save your trained model's state_dict() to file](#1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a57a951-16e8-4b46-baec-fb5f5eb3775c",
   "metadata": {
    "id": "Glu2fM4dkNlx"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cd6bd1-30e3-41af-9a5d-69e5ddd15a95",
   "metadata": {
    "id": "LqKhXY26m31s"
   },
   "outputs": [],
   "source": [
    "# Setup device-agnostic code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a51b13-ad99-4116-aff2-4c906cbbb2b7",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6a2de1-a295-45b9-866e-edb70f8d2c49",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-size:1em;\">1.1. Create a straight line dataset.</span>\n",
    "\n",
    "[Go back to the content](#1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e50302-6600-4d01-a288-a93647305c84",
   "metadata": {},
   "source": [
    "**The variants numbers are from 1 to 10:**\n",
    "\n",
    "1. Create a straight line dataset using the linear regression formula (y = 0.2*x + 1.1). The dataset should contain at least 120 data points, with 70% of the data used for training and the remaining 30% used for testing. Display both training and testing data on a visualization.\n",
    "\n",
    "2. Generate a straight line dataset using the linear regression formula (y = 0.4*x + 0.5). The dataset should contain at least 150 data points, with 80% of the data used for training and the remaining 20% used for testing. Display both training and testing data on a visualization.\n",
    "\n",
    "3. Create a straight line dataset using the linear regression formula (y = 0.7*x + 0.2). The dataset should contain at least 100 data points, with 75% of the data used for training and the remaining 25% used for testing. Display both training and testing data on a visualization.\n",
    "\n",
    "4. Generate a straight line dataset using the linear regression formula (y = 0.1*x + 1.2). The dataset should contain at least 200 data points, with 60% of the data used for training and the remaining 40% used for testing. Display both training and testing data on a visualization.\n",
    "\n",
    "5. Create a straight line dataset using the linear regression formula (y = 0.5*x - 0.1). The dataset should contain at least 130 data points, with 85% of the data used for training and the remaining 15% used for testing. Display both training and testing data on a visualization.\n",
    "\n",
    "6. Create a straight line dataset using the linear regression formula (y = 0.2*x + 1.0). The dataset should contain at least 150 data points, with 70% of the data used for training and the remaining 30% used for testing. Display both training and testing data on a visualization.\n",
    "\n",
    "7. Generate a straight line dataset using the linear regression formula (y = 0.4*x + 0.6). The dataset should contain at least 200 data points, with 75% of the data used for training and the remaining 25% used for testing. Display both training and testing data on a visualization.\n",
    "\n",
    "8. Create a straight line dataset using the linear regression formula (y = 0.6*x + 0.3). The dataset should contain at least 120 data points, with 80% of the data used for training and the remaining 20% used for testing. Display both training and testing data on a visualization.\n",
    "\n",
    "9. Generate a straight line dataset using the linear regression formula (y = 0.1*x + 1.5). The dataset should contain at least 180 data points, with 65% of the data used for training and the remaining 35% used for testing. Display both training and testing data on a visualization.\n",
    "\n",
    "10. Create a straight line dataset using the linear regression formula (y = 0.8*x + 0.1). The dataset should contain at least 250 data points, with 85% of the data used for training and the remaining 15% used for testing. Display both training and testing data on a visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26265fc2-d57f-42c4-ba89-84b9d42b8797",
   "metadata": {
    "id": "g7HUhxCxjeBx"
   },
   "source": [
    "Your output of the below cell should look something like:\n",
    "```\n",
    "Number of X samples: 100\n",
    "Number of y samples: 100\n",
    "First 10 X & y samples:\n",
    "X: tensor([0.0000, 0.0100, 0.0200, 0.0300, 0.0400, 0.0500, 0.0600, 0.0700, 0.0800,\n",
    "        0.0900])\n",
    "y: tensor([0.9000, 0.9030, 0.9060, 0.9090, 0.9120, 0.9150, 0.9180, 0.9210, 0.9240,\n",
    "        0.9270])\n",
    "```\n",
    "\n",
    "Of course the numbers in `X` and `y` may be different but ideally they're created using the linear regression formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c18c8c-e44f-4fdd-84f3-24a4c615441c",
   "metadata": {
    "id": "KbDG5MV7jhvE"
   },
   "outputs": [],
   "source": [
    "# Create the data parameters\n",
    "\n",
    "\n",
    "# Make X and y using linear regression feature\n",
    "\n",
    "\n",
    "print(f\"Number of X samples: {len(X)}\")\n",
    "print(f\"Number of y samples: {len(y)}\")\n",
    "print(f\"First 10 X & y samples:\\nX: {X[:10]}\\ny: {y[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f95f1-d5a4-4e34-9fd7-ac6fcc2ebdc9",
   "metadata": {
    "id": "GlwtT1djkmLw"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e5d9b8-dcd3-4e3a-a7e0-90c3d812bbc6",
   "metadata": {
    "id": "29iQZFNhlYJ-"
   },
   "outputs": [],
   "source": [
    "# Plot the training and testing data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603f6c73-d000-42b2-a1c8-4a9d7d8c933d",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd71c8e4-03f0-4c88-bb6d-353aeca84100",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-size:1em;\">1.2. Build a PyTorch model.</span>\n",
    "\n",
    "[Go back to the content](#1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3e6c67-9f89-4dc4-a639-bd3a70332a23",
   "metadata": {},
   "source": [
    "**The variants numbers are from 1 to 10:**\n",
    "\n",
    "1. Build a PyTorch model by subclassing `nn.Module`.\n",
    "    * Inside should be a randomly initialized `nn.Parameter()` with `requires_grad=True`, one for `weights` and one for `bias`.\n",
    "    * Implement the `forward()` method to compute the linear regression function you used to create the dataset in 1.\n",
    "    * Once you've constructed the model, make an instance of it and check its `state_dict()`.\n",
    "2. Build a PyTorch model by subclassing `nn.Module`.\n",
    "    * Inside should be a randomly initialized `nn.Parameter()` with `requires_grad=True`, one for `weights` and one for `bias`.\n",
    "    * Implement the `forward()` method to compute the linear regression function with `weight=0.6` and `bias=1.2`.\n",
    "    * Once you've constructed the model, make an instance of it and check its `state_dict()`.\n",
    "3. Build a PyTorch model by subclassing `nn.Module`.\n",
    "    * Inside should be a randomly initialized `nn.Parameter()` with `requires_grad=True`, one for `weights` and one for `bias`.\n",
    "    * Implement the `forward()` method to compute the linear regression function with `weight=1.0` and `bias=-0.5`.\n",
    "    * Once you've constructed the model, make an instance of it and check its `state_dict()`.\n",
    "4. Build a PyTorch model by subclassing `nn.Module`.\n",
    "    * Inside should be a randomly initialized `nn.Parameter()` with `requires_grad=True`, one for `weights` and one for `bias`.\n",
    "    * Implement the `forward()` method to compute the linear regression function with `weight=-0.2` and `bias=2.0`.\n",
    "    * Once you've constructed the model, make an instance of it and check its `state_dict()`.\n",
    "5. Build a PyTorch model by subclassing `nn.Module`.\n",
    "    * Inside should be a randomly initialized `nn.Parameter()` with `requires_grad=True`, one for `weights` and one for `bias`.\n",
    "    * Implement the `forward()` method to compute the linear regression function with weight=0.8 and `bias`=-1.0.\n",
    "    * Once you've constructed the model, make an instance of it and check its `state_dict()`.\n",
    "6. Build a PyTorch model by subclassing `nn.Module`.\n",
    "    * Inside should be a randomly initialized `nn.Parameter()` with `requires_grad=True`, one for `weights` and one for `bias`.\n",
    "    * Implement the `forward()` method to compute the linear regression function with weight=0.5 and `bias`=1.0.\n",
    "    * Once you've constructed the model, make an instance of it and check its `state_dict()`.\n",
    "7. Build a PyTorch model by subclassing `nn.Module`.\n",
    "    * Inside should be a randomly initialized `nn.Parameter()` with `requires_grad=True`, one for `weights` and one for `bias`.\n",
    "    * Implement the `forward()` method to compute the linear regression function with `weight=1.5` and `bias=0.5`.\n",
    "    * Once you've constructed the model, make an instance of it and check its `state_dict()`.\n",
    "8. Build a PyTorch model by subclassing `nn.Module`.\n",
    "    * Inside should be a randomly initialized `nn.Parameter()` with `requires_grad=True`, one for `weights` and one for `bias`.\n",
    "    * Implement the `forward()` method to compute the linear regression function with `weight=0.1` and `bias=-2.0`.\n",
    "    * Once you've constructed the model, make an instance of it and check its `state_dict()`.\n",
    "9. Build a PyTorch model by subclassing `nn.Module`.\n",
    "    * Inside should be a randomly initialized `nn.Parameter()` with `requires_grad=True`, one for `weights` and one for `bias`.\n",
    "    * Implement the `forward()` method to compute the linear regression function with `weight=1.0` and `bias=-0.5`.\n",
    "    * Once you've constructed the model, make an instance of it and check its `state_dict()`.\n",
    "10. Build a PyTorch model by subclassing `nn.Module`.\n",
    "    * Inside should be a randomly initialized `nn.Parameter()` with `requires_grad=True`, one for `weights` and one for `bias`.\n",
    "    * Implement the `forward()` method to compute the linear regression function with `weight=-0.5` and `bias=0.0`.\n",
    "    * Once you've constructed the model, make an instance of it and check its `state_dict()`.\n",
    "    \n",
    "**Note:** If you'd like to use `nn.Linear()` instead of `nn.Parameter()` you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320fda18-963a-42c8-9b70-1c1bd84bca70",
   "metadata": {
    "id": "qzd__Y5rjtB8"
   },
   "outputs": [],
   "source": [
    "# Create PyTorch linear regression model by subclassing `nn.Module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38180d31-31cf-46a1-8e93-a1b4e864f0cd",
   "metadata": {
    "id": "5LdcDnmOmyQ2"
   },
   "outputs": [],
   "source": [
    "# Instantiate the model and put it to the target device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050fe741-0528-46ed-909d-c3acd72273ff",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1.3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf146975-5f31-462e-8186-9fee8e7e0dc6",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-size:1em;\">1.3. Create a loss function and an optimizer.</span>\n",
    "\n",
    "[Go back to the content](#1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937a7822-066d-4651-a132-a8b608c8e4bd",
   "metadata": {},
   "source": [
    "**The variants numbers are from 1 to 10:**\n",
    "\n",
    "1. Create a loss function and optimizer using `nn.L1Loss()` and `torch.optim.SGD(params, lr)` respectively. Set the learning rate of the optimizer to be 0.001 and the parameters to optimize should be the model parameters from the model you created in 2. Write a training loop to perform the appropriate training steps for 500 epochs. The training loop should test the model on the test dataset every 25 epochs.\n",
    "\n",
    "2. Create a loss function and optimizer using `nn.L1Loss()` and `torch.optim.SGD(params, lr)` respectively. Set the learning rate of the optimizer to be 0.005 and the parameters to optimize should be the model parameters from the model you created in 2. Write a training loop to perform the appropriate training steps for 400 epochs. The training loop should test the model on the test dataset every 10 epochs.\n",
    "\n",
    "3. Create a loss function and optimizer using `nn.L1Loss()` and `torch.optim.SGD(params, lr)` respectively. Set the learning rate of the optimizer to be 0.001 and the parameters to optimize should be the model parameters from the model you created in 2. Write a training loop to perform the appropriate training steps for 200 epochs. The training loop should test the model on the test dataset every 15 epochs.\n",
    "\n",
    "4. Create a loss function and optimizer using `nn.L1Loss()` and `torch.optim.SGD(params, lr)` respectively. Set the learning rate of the optimizer to be 0.01 and the parameters to optimize should be the model parameters from the model you created in 2. Write a training loop to perform the appropriate training steps for 500 epochs. The training loop should test the model on the test dataset every 50 epochs.\n",
    "\n",
    "5. Create a loss function and optimizer using `nn.L1Loss()` and `torch.optim.SGD(params, lr)` respectively. Set the learning rate of the optimizer to be 0.002 and the parameters to optimize should be the model parameters from the model you created in 2. Write a training loop to perform the appropriate training steps for 300 epochs. The training loop should test the model on the test dataset every 30 epochs.\n",
    "\n",
    "6. Create a loss function and optimizer using `nn.L1Loss()` and `torch.optim.SGD(params, lr)` respectively. Set the learning rate of the optimizer to be 0.001 and the parameters to optimize should be the model parameters from the model you created in 2. Write a training loop to perform the appropriate training steps for 500 epochs. The training loop should test the model on the test dataset every 25 epochs.\n",
    "\n",
    "7. Create a loss function and optimizer using `nn.L1Loss()` and `torch.optim.SGD(params, lr)` respectively. Set the learning rate of the optimizer to be 0.05 and the parameters to optimize should be the model parameters from the model you created in 2. Write a training loop to perform the appropriate training steps for 400 epochs. The training loop should test the model on the test dataset every 10 epochs.\n",
    "\n",
    "8. Create a loss function and optimizer using `nn.L1Loss()` and `torch.optim.SGD(params, lr)` respectively. Set the learning rate of the optimizer to be 0.0015 and the parameters to optimize should be the model parameters from the model you created in 2. Write a training loop to perform the appropriate training steps for 200 epochs. The training loop should test the model on the test dataset every 15 epochs.\n",
    "\n",
    "9. Create a loss function and optimizer using `nn.L1Loss()` and `torch.optim.SGD(params, lr)` respectively. Set the learning rate of the optimizer to be 0.005 and the parameters to optimize should be the model parameters from the model you created in 2. Write a training loop to perform the appropriate training steps for 500 epochs. The training loop should test the model on the test dataset every 50 epochs.\n",
    "\n",
    "10. Create a loss function and optimizer using `nn.L1Loss()` and `torch.optim.SGD(params, lr)` respectively. Set the learning rate of the optimizer to be 0.02 and the parameters to optimize should be the model parameters from the model you created in 2. Write a training loop to perform the appropriate training steps for 300 epochs. The training loop should test the model on the test dataset every 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2201c276-df53-4aab-99db-68cc74da2507",
   "metadata": {
    "id": "ltvoZ-FWjv1j"
   },
   "outputs": [],
   "source": [
    "# Create the loss function and optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af84f9c0-b3ef-4ec4-9678-1a0bb1b00fa5",
   "metadata": {
    "id": "xpE83NvNnkdV"
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "\n",
    "# Train model for 300 epochs\n",
    "\n",
    "\n",
    "# Send data to target device\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  ### Training\n",
    "\n",
    "  # Put model in train mode\n",
    "  \n",
    "\n",
    "  # 1. Forward pass\n",
    "  \n",
    "\n",
    "  # 2. Calculate loss\n",
    "  \n",
    "\n",
    "  # 3. Zero gradients\n",
    "  \n",
    "\n",
    "  # 4. Backpropagation\n",
    "  \n",
    "\n",
    "  # 5. Step the optimizer\n",
    "  \n",
    "\n",
    "  ### Perform testing every 20 epochs\n",
    "  if epoch % 20 == 0:\n",
    "\n",
    "    # Put model in evaluation mode and setup inference context \n",
    "    \n",
    "      # 1. Forward pass\n",
    "      \n",
    "      # 2. Calculate test loss\n",
    "\n",
    "      # Print out what's happening\n",
    "      print(f\"Epoch: {epoch} | Train loss: {loss:.3f} | Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b40429-41e9-4dfd-8cc6-a17c45a66d65",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1.4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4577912-969b-4c5e-a695-a80eeac32fac",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-size:1em;\">1.4. Make predictions with the trained model on the test data.</span>\n",
    "\n",
    "[Go back to the content](#1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c018ad0a-5dea-42e3-a5dd-f40c0414c00f",
   "metadata": {},
   "source": [
    "**This task is similar for all variants.**\n",
    "\n",
    "Visualize the obtained predictions against the original training and testing data (**note:** you may need to make sure the predictions are *not* on the GPU if you want to use non-CUDA-enabled libraries such as matplotlib to plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac3ed3-3393-41ce-a895-726d9d208791",
   "metadata": {
    "id": "bbMPK5Qjjyx_"
   },
   "outputs": [],
   "source": [
    "# Make predictions with the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0758d2d2-26b3-4084-9d9e-9c001364e969",
   "metadata": {
    "id": "K3BdmQaDpFo8"
   },
   "outputs": [],
   "source": [
    "# Plot the predictions (these may need to be on a specific device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca31ca4a-4484-4009-8afb-267225331b9d",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1.5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb619fc-e4d3-4da0-b7a7-77a3273750e2",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-size:1em;\">1.5. Save your trained model's state_dict() to file.</span>\n",
    "\n",
    "[Go back to the content](#1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae62997-e4f8-428a-9356-cf5d999549ec",
   "metadata": {},
   "source": [
    "**This task is similar for all variants.**\n",
    "\n",
    "Save your trained model's `state_dict()` to a file named \"my_model_weights.pth\". Create a new instance of your model class you made in Task 2 and load in the state_dict() you just saved to it. Perform predictions on your test data with the loaded model and confirm they match the original model predictions from Task 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb12e61-3362-4822-963f-d48d63b75971",
   "metadata": {
    "id": "hgxhgD14qr-i"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 1. Create models directory \n",
    "\n",
    "\n",
    "# 2. Create model save path \n",
    "\n",
    "# 3. Save the model state dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7bf1dc-d55d-42f6-b66e-a7428c6c0ef8",
   "metadata": {
    "id": "P9vTgiLRrJ7T"
   },
   "outputs": [],
   "source": [
    "# Create new instance of model and load saved state dict (make sure to put it on the target device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce013c-5e4c-4277-bd98-7f7819b2acb0",
   "metadata": {
    "id": "8UGX3VebrVtI"
   },
   "outputs": [],
   "source": [
    "# Make predictions with loaded model and compare them to the previous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c871bfd-7694-49c4-ac8e-fabbd3d94ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
