{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Laboratory work 5.</center></h1>\n",
    "<h2><center>PyTorch Custom Datasets Exercises</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performed:** Last name and First name\n",
    "\n",
    "**Variant:** #__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "\n",
    "1. [Task 1. Preparing data](#5.1)\n",
    "2. [Task 2. Creating a model](#5.2)\n",
    "3. [Task 3. Training and testing loops](#5.3)\n",
    "4. [Task 4. Conducting experiments with hyperparameters](#5.4)\n",
    "5. [Task 5. Conducting experiments with the model's layers](#5.5)\n",
    "6. [Task 6. Conducting experiments with the data](#5.6)\n",
    "7. [Task 6. Making predictions](#5.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "DNwZLMbCzJLk",
    "outputId": "1a7b73e2-ec4b-41b0-b4da-c3216a8a29ac"
   },
   "outputs": [],
   "source": [
    "# Import torch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Exercises require PyTorch > 1.10.0\n",
    "print(torch.__version__)\n",
    "\n",
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"5.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-90Qvx9gtrLj"
   },
   "source": [
    "## <span style=\"color:blue; font-size:1em;\"> Task 1. Preparing data</span>\n",
    "\n",
    "[Go back to the content](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For variant 1:** Recreate the data loading functions we built in sections 1-4 of [notebook 05](https://github.com/radiukpavlo/conducting-experiments/blob/main/01_notebooks/ce_05_pytorch_custom_datasets.ipynb). By this time, you should have had the trained and tested `DataLoader`'s ready to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZkCPJBR3lw4"
   },
   "outputs": [],
   "source": [
    "# 1. Get data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYmhAX7J52VX"
   },
   "outputs": [],
   "source": [
    "# 2. Become one with the data\n",
    "import os\n",
    "def walk_through_dir(dir_path):\n",
    "  \"\"\"Walks through dir_path returning file counts of its contents.\"\"\"\n",
    "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3A9ZmOn-7Jhh"
   },
   "outputs": [],
   "source": [
    "# Setup train and testing paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "51ywNKkN7WOl"
   },
   "outputs": [],
   "source": [
    "# Visualize an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qe4LoASC9sQ-"
   },
   "outputs": [],
   "source": [
    "# Do the image visualization with matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AU4FGYC_KBz"
   },
   "source": [
    "We've got some images in our folders.\n",
    "\n",
    "Now we need to make them compatible with PyTorch by:\n",
    "1. Transform the data into tensors.\n",
    "2. Turn the tensor data into a `torch.utils.data.Dataset` and later a `torch.utils.data.DataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KbGMaYGT-vwq"
   },
   "outputs": [],
   "source": [
    "# 3.1 Transforming data with torchvision.transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gnvUSYYW_ohN"
   },
   "outputs": [],
   "source": [
    "# Write transform for turning images into tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vp8I2cpMAxcT"
   },
   "outputs": [],
   "source": [
    "# Write a function to plot transformed images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKgfqPArChVR"
   },
   "source": [
    "### Load image data using `ImageFolder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8OFgwQF1CkOu"
   },
   "outputs": [],
   "source": [
    "# Use ImageFolder to create dataset(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MbT0fhXHEQyJ",
    "outputId": "ad2b0da9-285c-493d-c362-a6b00e5d2197"
   },
   "outputs": [],
   "source": [
    "# Get class names as a list\n",
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uCcWk7NDEay1",
    "outputId": "88718fd6-c6b2-4132-9383-0a64a0a7bcee"
   },
   "outputs": [],
   "source": [
    "# Can also get class names as a dict\n",
    "class_dict = train_data.class_to_idx\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W7H7bX4HEgie",
    "outputId": "2ff1fdd2-f990-461d-c2e9-27435e7744c9"
   },
   "outputs": [],
   "source": [
    "# Check the lengths of each dataset\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nskNr5YCEoRl",
    "outputId": "cd825b1d-095f-4080-86ce-7d17aafef7e8"
   },
   "outputs": [],
   "source": [
    "# Turn train and test Datasets into DataLoaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z8vJxmxAFqw6",
    "outputId": "e5a8bd88-1b05-4109-de5a-8183a85c7872"
   },
   "outputs": [],
   "source": [
    "# How many batches of images are in our data loaders?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"5.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-size:1em;\"> Task 2. Creating a model</span>\n",
    "\n",
    "[Go back to the content](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For variant 1:** Recreate `model_0` we built in section 7 of notebook_05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"5.3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-size:1em;\"> Task 3. Training and testing loops</span>\n",
    "\n",
    "[Go back to the content](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For variant 1:** Create training and testing functions for `model_0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnUox1qayDes"
   },
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer):\n",
    "  \n",
    "  # Put the model in train mode\n",
    "  model.train()\n",
    "\n",
    "  # Setup train loss and train accuracy values\n",
    "  train_loss, train_acc = 0, 0\n",
    "\n",
    "  # Loop through data loader and data batches\n",
    " \n",
    "    # Send data to target device\n",
    "\n",
    "    # 1. Forward pass\n",
    "    \n",
    "    # 2. Calculate and accumulate loss\n",
    "    \n",
    "\n",
    "    # 3. Optimizer zero grad \n",
    "    \n",
    "\n",
    "    # 4. Loss backward \n",
    "    \n",
    "\n",
    "    # 5. Optimizer step\n",
    "    \n",
    "\n",
    "    # Calculate and accumualte accuracy metric across all batches\n",
    "   \n",
    "\n",
    "  # Adjust metrics to get average loss and average accuracy per batch\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7_EVPpHNKUP"
   },
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module):\n",
    "  \n",
    "  # Put model in eval mode\n",
    "  model.eval()\n",
    "\n",
    "  # Setup the test loss and test accuracy values\n",
    "  test_loss, test_acc = 0, 0\n",
    "\n",
    "  # Turn on inference context manager\n",
    "  \n",
    "    # Loop through DataLoader batches\n",
    "    \n",
    "      # Send data to target device\n",
    "      \n",
    "\n",
    "      # 1. Forward pass\n",
    "      \n",
    "\n",
    "      # 2. Calculuate and accumulate loss\n",
    "\n",
    "\n",
    "      # Calculate and accumulate accuracy\n",
    "\n",
    "    \n",
    "  # Adjust metrics to get average loss and accuracy per batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zXxTIh9tOh68"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          epochs: int = 5):\n",
    "  \n",
    "  # Create results dictionary\n",
    "  results = {\"train_loss\": [],\n",
    "             \"train_acc\": [],\n",
    "             \"test_loss\": [],\n",
    "             \"test_acc\": []}\n",
    "\n",
    "  # Loop through the training and testing steps for a number of epochs\n",
    "  for epoch in tqdm(range(epochs)):\n",
    "    # Train step\n",
    "    train_loss, train_acc = train_step(model=model, \n",
    "                                       dataloader=train_dataloader,\n",
    "                                       loss_fn=loss_fn,\n",
    "                                       optimizer=optimizer)\n",
    "    # Test step\n",
    "    test_loss, test_acc = test_step(model=model, \n",
    "                                    dataloader=test_dataloader,\n",
    "                                    loss_fn=loss_fn)\n",
    "    \n",
    "    # Print out what's happening\n",
    "    print(f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Update the results dictionary\n",
    "    results[\"train_loss\"].append(train_loss)\n",
    "    results[\"train_acc\"].append(train_acc)\n",
    "    results[\"test_loss\"].append(test_loss)\n",
    "    results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "  # Return the results dictionary\n",
    "  return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"5.4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-size:1em;\"> Task 4. Conducting experiments with hyperparameters</span>\n",
    "\n",
    "[Go back to the content](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For variant 1:** Train the model you made in the previous exercise for 5, 20 and 50 epochs. Use `torch.optim.Adam()` with a learning rate of 0.001 as the optimizer. What happens to the results?."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the model might be starting to overfit towards the end (performing far better on the training data than on the testing data).\n",
    "\n",
    "In order to fix this, we'd have to introduce ways of preventing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"5.5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-size:1em;\"> Task 5. Conducting experiments with the model's layers</span>\n",
    "\n",
    "[Go back to the content](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For variant 1:** Double the number of hidden units in your model and train it for 20 epochs. What happens to the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THYGHbxyTfzM"
   },
   "source": [
    "It looks like the model might be overfitting, even when changing the number of hidden units.\n",
    "\n",
    "To fix this, we'd have to look at ways to prevent overfitting with our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"5.6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-size:1em;\"> Task 6. Conducting experiments with the data</span>\n",
    "\n",
    "[Go back to the content](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For variant 1:** Try to double the data you're using with your model from exercise 5 and train it for 20 epochs. What happens to the results?\n",
    "* **Note:** You can use the [custom data creation notebook](https://github.com/radiukpavlo/conducting-experiments/blob/main/01_notebooks/ce_05_pytorch_custom_datasets.ipynb) to scale up your Food101 dataset.\n",
    "* You can also find the [already formatted double data (20% instead of 10% subset) dataset on GitHub](https://github.com/radiukpavlo/conducting-experiments/blob/main/data/pizza_steak_sushi_20_percent.zip). However, you will need to write down the code like in exercise 1 to get it into this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8tWfa7Y0yCkX"
   },
   "outputs": [],
   "source": [
    "# Download 20% data for Pizza/Steak/Sushi from GitHub\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup path to data folder\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi_20_percent\"\n",
    "\n",
    "# If the image folder doesn't exist, download it and prepare it... \n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory exists.\")\n",
    "else:\n",
    "    print(f\"Did not find {image_path} directory, creating one...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "# Download pizza, steak, sushi data\n",
    "with open(data_path / \"pizza_steak_sushi_20_percent.zip\", \"wb\") as f:\n",
    "    request = requests.get(\"https://github.com/radiukpavlo/applied-math-packages/blob/main/data/pizza_steak_sushi_20_percent.zip\")\n",
    "    print(\"Downloading pizza, steak, sushi 20% data...\")\n",
    "    f.write(request.content)\n",
    "\n",
    "# Unzip pizza, steak, sushi data\n",
    "with zipfile.ZipFile(data_path / \"pizza_steak_sushi_20_percent.zip\", \"r\") as zip_ref:\n",
    "    print(\"Unzipping pizza, steak, sushi 20% data...\") \n",
    "    zip_ref.extractall(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DrFK2ScnVg4q"
   },
   "outputs": [],
   "source": [
    "# See how many images we have\n",
    "walk_through_dir(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WhlWd-z-Vk22"
   },
   "source": [
    "Excellent, we now have double the training and testing images... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hNzXRfO1Tt1Q"
   },
   "outputs": [],
   "source": [
    "# Create the train and test paths\n",
    "train_data_20_percent_path = image_path / \"train\"\n",
    "test_data_20_percent_path = image_path / \"test\"\n",
    "\n",
    "train_data_20_percent_path, test_data_20_percent_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1_xU3FQUPkN"
   },
   "outputs": [],
   "source": [
    "# Turn the 20 percent datapaths into Datasets and DataLoaders\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "simple_transform = transforms.Compose([\n",
    "  transforms.Resize((64, 64)),                                     \n",
    "  transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "\n",
    "\n",
    "# Create dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BuJ9YpRCVXRm"
   },
   "outputs": [],
   "source": [
    "# Train a model with increased amount of data\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"5.7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-size:1em;\"> Task 7. Making predictions</span>\n",
    "\n",
    "[Go back to the content](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For variant 1:** Make a prediction on your own custom image of pizza/steak/sushi (you could even download one from the internet) with your trained model from exercise 6 and share your prediction. \n",
    "* Does the model you trained in exercise 6 get it right? \n",
    "* If not, what do you think you could do to improve it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1X-33t0vT20"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO06uacGGDzw0TkyZ8mqgSU",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "04_pytorch_custom_datasets_exercises.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
