{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Laboratory work 6.</center></h1>\n",
    "<h2><center>PyTorch Going Modular Exercises</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performed:** Last name and First name\n",
    "\n",
    "**Variant:** #__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "\n",
    "1. [Task 1. Preparing data](#6.1)\n",
    "2. [Task 2. Creating a model](#6.2)\n",
    "3. [Task 3. Training and testing loops](#6.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"6.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-size:1em;\"> Task 1. Preparing data</span>\n",
    "\n",
    "[Go back to the content](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bicbWSrPmfTU"
   },
   "source": [
    "**For all variants:** Turn the code to get the data (from section [1. Get Data](https://github.com/radiukpavlo/conducting-experiments/blob/main/01_notebooks/ce_06_pytorch_going_modular.md)) into a Python script, such as `get_data.py`.\n",
    "\n",
    "* When you run the script using `python get_data.py` it should check if the data already exists and skip downloading if it does.\n",
    "* If the data download is successful, you should be able to access the `pizza_steak_sushi` images from the `data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "r0BCn1XIYZ8c"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_LrUOIC-YOP9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'C:\\Courses\\conducting-experiments-test\\02_assignments\\get_data.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Example running of get_data.py\n",
    "!python get_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"6.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-size:1em;\"> Task 2. Creating and modifying a model</span>\n",
    "\n",
    "[Go back to the content](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For all variants:** Use [Python's `argparse` module](https://docs.python.org/3/library/argparse.html) to be able to send the `train.py` custom hyperparameter values for training procedures.\n",
    "\n",
    "* Add an argument flag for using different hyperparameters.\n",
    "* Keep the default values for each of the above arguments as what they already are (as in notebook 05).\n",
    "* For example, you should be able to run something similar to the following line to train a TinyVGG model with a learning rate of 0.003 and a batch size of 64 for 20 epochs: `python train.py --learning_rate 0.003 batch_size 64 num_epochs 20`.\n",
    "\n",
    "**Note:** Since `train.py` leverages the other scripts we created in section 06, such as, `model_builder.py`, `utils.py` and `engine.py`, you will have to make sure they are available to use too. You can find these in the [`going_modular` folder on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/going_modular/going_modular). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjyn7LU3mvkR"
   },
   "source": [
    "**For variant 1-3:** Training with Different Learning Rate and Batch Size\n",
    "\n",
    "Here, you need to understand how these hyperparameters impact the training process and model performance.\n",
    "\n",
    "```bash\n",
    "# Example running of train.py\n",
    "python train.py --learning_rate 0.001 --batch_size 32 --num_epochs 10 --hidden_units 128\n",
    "```\n",
    "\n",
    "You need to modify the `train.py` script to accept command-line arguments for `learning_rate`, `batch_size`, `num_epochs`, and `hidden_units` using the `argparse` module. In this case, the learning rate must be set to 0.001, and the batch size must be set to 32. The number of epochs is 10, and the number of hidden units in the TinyVGG model is 128. By adjusting the learning rate and batch size, you need to observe how the model's convergence speed and final accuracy are affected.\n",
    "\n",
    "**For variant 4-6:** Training with Different Number of Epochs and Hidden Units\n",
    "\n",
    "You must emphasize the effect of training for different numbers of epochs and using different hidden units in the model.\n",
    "\n",
    "```bash\n",
    "# Example running of train.py\n",
    "python train.py --learning_rate 0.01 --batch_size 64 --num_epochs 50 --hidden_units 256\n",
    "```\n",
    "\n",
    "In this case, the learning rate must be set to 0.01, and the batch size is 64. The number of epochs is increased to 50, and the number of hidden units in the TinyVGG model is 256. By increasing the number of epochs, you need to observe how the model continues to learn over a more extended period, potentially improving accuracy but also risking overfitting. The increased number of hidden units allows the model to capture more complex patterns in the data. You need to analyze the impact of these changes on the training time, model performance, and overfitting.\n",
    "\n",
    "**For variant 7-9:** Training with a Different Directory\n",
    "\n",
    "In this case, you need to observe how to train the model using a different dataset directory, which is useful for working with various datasets without changing the code.\n",
    "\n",
    "```bash\n",
    "# Example running of train.py\n",
    "python train.py --data_dir ./new_data --learning_rate 0.005 --batch_size 128 --num_epochs 30 --hidden_units 512\n",
    "```\n",
    "\n",
    "Here, the `data_dir` argument is introduced to specify a different directory for the training and testing datasets. The learning rate must be set to 0.005, the batch size is 128, the number of epochs is 30, and the number of hidden units in the TinyVGG model is 512.\n",
    "\n",
    "**For variant 10-12:** Training with a Very High Learning Rate\n",
    "\n",
    "In this case, you need to experiment with a very high learning rate to observe the effects on the training process and model performance.\n",
    "\n",
    "```bash\n",
    "# Example running of train.py\n",
    "python train.py --learning_rate 0.1 --batch_size 16 --num_epochs 20 --hidden_units 64\n",
    "```\n",
    "\n",
    "The learning rate must be set to a high value of 0.1, with a batch size of 16, 20 epochs, and 64 hidden units in the TinyVGG model. By using a very high learning rate, you need to likely observe unstable training, with the loss fluctuating significantly and potentially not converging. This variant illustrates the importance of choosing an appropriate learning rate and the consequences of setting it too high. You need to learn to monitor training metrics and adjust hyperparameters to achieve stable and effective training.\n",
    "\n",
    "**For variant 13-15:** Training with a Very Low Learning Rate\n",
    "\n",
    "In this case, you need to explore the impact of using a very low learning rate, which can lead to slow convergence but potentially better final performance.\n",
    "\n",
    "```bash\n",
    "# Example running of train.py\n",
    "python train.py --learning_rate 0.0001 --batch_size 128 --num_epochs 100 --hidden_units 128\n",
    "```\n",
    "\n",
    "In this case, the learning rate must be set to a very low value of 0.0001, with a batch size of 128, 100 epochs, and 128 hidden units in the TinyVGG model. Using a very low learning rate results in slow convergence, requiring more epochs to reach a similar performance level compared to higher learning rates. However, this approach can lead to better final performance and stability, as the model makes smaller, more precise updates to its parameters. You need to understand the trade-offs between learning rate, convergence speed, and model performance, gaining insights into tuning hyperparameters for optimal training results.\n",
    "\n",
    "**For variant 6:** Training with Mixed Precision\n",
    "\n",
    "In this case, you must introduce the option to use mixed precision training, which can speed up training and reduce memory usage.\n",
    "\n",
    "```bash\n",
    "# Example running of train.py\n",
    "python train.py --learning_rate 0.002 --batch_size 64 --num_epochs 15 --hidden_units 256 --mixed_precision True\n",
    "```\n",
    "\n",
    "In this case, the learning rate must be set to 0.002, batch size to 64, number of epochs to 15, and hidden units in the TinyVGG model to 256. Additionally, a new argument `--mixed_precision` is introduced to enable mixed precision training. Mixed precision training uses half-precision floating-point numbers (float16) alongside single-precision (float32) to reduce memory usage and increase computational efficiency. You need to modify the `train.py` script to include the use of `torch.cuda.amp` for automatic mixed precision, which can lead to faster training times and reduced memory consumption on GPUs. You need to observe the benefits and any potential trade-offs when using mixed precision.\n",
    "\n",
    "**For variant 19-21:** Training with Different Optimizers\n",
    "\n",
    "In this case, you need to experiment with different optimizers to understand their impact on model training.\n",
    "\n",
    "```bash\n",
    "# Example running of train.py\n",
    "python train.py --learning_rate 0.01 --batch_size 32 --num_epochs 25 --hidden_units 128 --optimizer Adam\n",
    "```\n",
    "\n",
    "In this case, the learning rate must be set to 0.01, batch size to 32, number of epochs to 25, and hidden units in the TinyVGG model to 128. An additional argument `--optimizer` is introduced, allowing you to choose from different optimizers like `SGD`, `Adam`, or `RMSprop`. For this example, the `Adam` optimizer is selected. You need to modify the `train.py` script to accept the optimizer argument and dynamically create the optimizer instance based on the provided value. You need to compare the performance of different optimizers, understanding how each optimizer affects the convergence rate and final accuracy of the model.\n",
    "\n",
    "**For variant 8:** Training with Early Stopping\n",
    "\n",
    "In this case, you need to introduce early stopping to prevent overfitting by stopping training when the validation performance stops improving.\n",
    "\n",
    "```bash\n",
    "# Example running of train.py\n",
    "python train.py --learning_rate 0.005 --batch_size 64 --num_epochs 50 --hidden_units 256 --early_stopping True\n",
    "```\n",
    "\n",
    "The learning rate must be set to 0.005, batch size to 64, number of epochs to 50, and hidden units in the TinyVGG model to 256. A new argument `--early_stopping` is introduced to enable early stopping. You need to modify the `train.py` script to monitor validation loss during training and stop the training process if the validation loss does not improve for a specified number of epochs (patience). You need to implement early stopping logic using a simple counter to track the number of epochs since the last improvement. Likewise, you should understand here how early stopping can prevent overfitting and save computational resources by terminating training early when further improvements are unlikely.\n",
    "\n",
    "**For variant 25-27:** Training with Data Augmentation\n",
    "\n",
    "In this case, you need to use data augmentation to improve model generalization by artificially expanding the training dataset.\n",
    "\n",
    "```bash\n",
    "# Example running of train.py\n",
    "python train.py --learning_rate 0.002 --batch_size 128 --num_epochs 30 --hidden_units 512 --data_augmentation True\n",
    "```\n",
    "\n",
    "The learning rate must be set to 0.002, batch size to 128, number of epochs to 30, and hidden units in the TinyVGG model to 512. An additional argument `--data_augmentation` is introduced to enable data augmentation. You need to modify the `train.py` script to apply various data augmentation techniques such as random cropping, flipping, rotation, and color jittering to the training data using `torchvision.transforms`. Data augmentation increases the diversity of the training data, which can help the model generalize better to unseen data. You need to observe how data augmentation impacts the model's training performance and final accuracy, gaining insights into techniques for improving model robustness.\n",
    "\n",
    "**For variant 28-30:** Training with Learning Rate Schedulers\n",
    "\n",
    "In this case, you need to introduce learning rate schedulers to dynamically adjust the learning rate during training based on the training progress.\n",
    "\n",
    "```bash\n",
    "# Example running of train.py\n",
    "python train.py --learning_rate 0.01 --batch_size 32 --num_epochs 40 --hidden_units 128 --scheduler StepLR --step_size 10 --gamma 0.1\n",
    "```\n",
    "\n",
    "The learning rate must be set to 0.01, batch size to 32, number of epochs to 40, and hidden units in the TinyVGG model to 128. New arguments `--scheduler`, `--step_size`, and `--gamma` are introduced to configure a learning rate scheduler. In this example, the `StepLR` scheduler is used with a `step_size` of 10 and a `gamma` of 0.1. You need to modify the `train.py` script to accept these arguments and implement the selected learning rate scheduler using `torch.optim.lr_scheduler`. The scheduler will adjust the learning rate after every specified number of epochs (`step_size`), multiplying it by the factor `gamma`. You need to understand how learning rate scheduling can improve training stability and performance by reducing the learning rate as training progresses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"6.3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue; font-size:1em;\"> Task 3. Making predictions</span>\n",
    "\n",
    "[Go back to the content](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For all variants:** Create a Python script to predict (such as `predict.py`) on a target image given a file path with a saved model.\n",
    "\n",
    "* For example, you should be able to run the command `python predict.py some_image.jpeg` and have a trained PyTorch model predict on the image and return its prediction.\n",
    "* To see example prediction code, check out the [predicting on a custom image section in notebook 05](https://github.com/radiukpavlo/conducting-experiments/blob/main/01_notebooks/ce_05_pytorch_custom_datasets.ipynb). \n",
    "* You may also have to write code to load in a trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2g6EEYvm-46"
   },
   "source": [
    "**For variant 1-3:** Predict with Specified Model Checkpoint\n",
    "\n",
    "In this case, you need to specify a model checkpoint file to load the model from, providing flexibility in using different trained models for prediction.\n",
    "\n",
    "```bash\n",
    "# Example running of predict.py \n",
    "python predict.py --image data/pizza_steak_sushi/test/sushi/175783.jpg --checkpoint models/best_model.pth\n",
    "```\n",
    "\n",
    "In this case, the script `predict.py` must be modified to accept an additional argument `--checkpoint` to specify the path to the model checkpoint file. You need to write code to load the trained model from the given checkpoint file using `torch.load`. You must enable the use of different models for prediction by simply changing the checkpoint file path, making it easier to compare the performance of various trained models.\n",
    "\n",
    "**For variant 4-6:** Predict with Different Image Size\n",
    "\n",
    "In this case, you need to specify the input image size to which the target image should be resized before prediction.\n",
    "\n",
    "```bash\n",
    "# Example running of predict.py \n",
    "python predict.py --image data/pizza_steak_sushi/test/sushi/175783.jpg --image_size 224\n",
    "```\n",
    "\n",
    "In this case, the script `predict.py` must be modified to accept an additional argument `--image_size` to specify the size to which the input image should be resized. Your code must use `torchvision.transforms` to resize the image to the given size before making a prediction. You must experiment with different input image sizes to understand their impact on the prediction accuracy and performance of the model.\n",
    "\n",
    "**For variant 7-9:** Predict with Multiple Images\n",
    "\n",
    "You need to predict on multiple images by specifying a directory containing the images.\n",
    "\n",
    "```bash\n",
    "# Example running of predict.py \n",
    "python predict.py --image_dir data/pizza_steak_sushi/test/sushi\n",
    "```\n",
    "\n",
    "In this case, the script `predict.py` must be modified to accept an argument `--image_dir` to specify a directory containing multiple images. Your code must loop through all images in the specified directory, make predictions for each image, and output the results. You need to perform batch predictions and valuate the model on a larger set of images without having to run the script multiple times for individual images.\n",
    "\n",
    "**For variant 10-12:** Predict with Confidence Threshold\n",
    "\n",
    "In this case, you need to introduce a confidence threshold to filter predictions, displaying only those with a confidence score above the specified threshold.\n",
    "\n",
    "```bash\n",
    "# Example running of predict.py \n",
    "python predict.py --image data/pizza_steak_sushi/test/sushi/175783.jpg --threshold 0.8\n",
    "```\n",
    "\n",
    "Here, the script `predict.py` must be modified to accept an additional argument `--threshold` to specify a confidence threshold. Your code must output predictions only if the confidence score is above the given threshold. You must filter out low-confidence predictions, making it easier to trust the model's outputs. It is particularly useful in applications where high confidence is crucial for decision-making.\n",
    "\n",
    "**For variant 13-15:** Predict with Class Labels Mapping\n",
    "\n",
    "You need to include a mapping of class labels to human-readable names for better interpretation of predictions.\n",
    "\n",
    "```bash\n",
    "# Example running of predict.py \n",
    "python predict.py --image data/pizza_steak_sushi/test/sushi/175783.jpg --labels_file labels.txt\n",
    "```\n",
    "\n",
    "In this case, the script `predict.py` must be modified to accept an additional argument `--labels_file` to specify a file containing the mapping of class labels to human-readable names. Your code must read the labels file and map the predicted class indices to the corresponding class names. You need to improve the interpretability of the predictions by providing meaningful class names instead of numeric indices. The `labels.txt` file should contain a list of class names, one per line, corresponding to the class indices used during training.\n",
    "\n",
    "**For variant 6:** Predict with GPU/CPU Option\n",
    "\n",
    "In this case, you need to specify whether to use a GPU or CPU for making predictions, providing flexibility in running the script on different hardware setups.\n",
    "\n",
    "```bash\n",
    "# Example running of predict.py \n",
    "python predict.py --image data/pizza_steak_sushi/test/sushi/175783.jpg --device cuda\n",
    "```\n",
    "\n",
    "In this case, the script `predict.py` must be modified to accept an additional argument `--device` to specify whether to use a GPU (`cuda`) or CPU (`cpu`) for making predictions. Your code must check the specified device and move the model and input data accordingly before making a prediction. This variant allows leveraging GPU acceleration for faster predictions when available, while also providing the option to run on CPU if a GPU is not available.\n",
    "\n",
    "**For variant 19-21:** Predict with Top-K Predictions\n",
    "\n",
    "Here, you need to provide the top-K predictions instead of just the top-1 prediction, giving a broader view of the model's outputs.\n",
    "\n",
    "```bash\n",
    "# Example running of predict.py \n",
    "python predict.py --image data/pizza_steak_sushi/test/sushi/175783.jpg --top_k 3\n",
    "```\n",
    "\n",
    "In this case, the script `predict.py` must be modified to accept an additional argument `--top_k` to specify the number of top predictions to return. Your code must sort the prediction probabilities and output the top-K classes along with their confidence scores. This case helps in understanding the model's uncertainty and provides a ranked list of possible predictions, which can be useful in applications where multiple plausible outcomes are expected.\n",
    "\n",
    "**For variant 8:** Predict with Output to File\n",
    "\n",
    "You need to output the prediction results to a specified file instead of printing them to the console, allowing for better logging and analysis.\n",
    "\n",
    "```bash\n",
    "# Example running of predict.py \n",
    "python predict.py --image data/pizza_steak_sushi/test/sushi/175783.jpg --output_file predictions.txt\n",
    "```\n",
    "\n",
    "In this case, the script `predict.py` must be modified to accept an additional argument `--output_file` to specify a file to save the prediction results. Your code must write the prediction results, including the predicted class and confidence score, to the specified file. You must provide logging predictions and analyzing the results later, especially when making predictions on a large number of images.\n",
    "\n",
    "**For variant 25-27:** Predict with Image Preprocessing Options\n",
    "\n",
    "In this case, you need to specify different image preprocessing options such as normalization values and color conversion.\n",
    "\n",
    "```bash\n",
    "# Example running of predict.py \n",
    "python predict.py --image data/pizza_steak_sushi/test/sushi/175783.jpg --normalize_mean 0.485 0.456 0.406 --normalize_std 0.229 0.224 0.225\n",
    "```\n",
    "In this case, the script `predict.py` must be modified to accept additional arguments `--normalize_mean` and `--normalize_std` to specify the mean and standard deviation values for image normalization. Your code must use these values to normalize the input image before making a prediction. You must experiment with different normalization parameters, which can impact the model's performance. You should also specify whether to convert the image to grayscale or keep it in color, providing flexibility in preprocessing steps.\n",
    "\n",
    "**For variant 28-30:** Predict with Interactive Mode\n",
    "\n",
    "You need to provide an interactive mode where users can input image paths one at a time and receive predictions in real-time.\n",
    "\n",
    "```bash\n",
    "# Example running of predict.py \n",
    "python predict.py --interactive\n",
    "```\n",
    "\n",
    "In this case, the script `predict.py` must be modified to include an interactive mode, activated by the `--interactive` argument. When run in interactive mode, the script must prompt the user to input image paths one at a time and output predictions for each image in real-time. Your code have to loop until the user decides to exit. Here, you need to quickly test predictions on various images without restarting the script, providing a convenient way to interactively evaluate the model's performance."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNcX0JATB1YsaAFGNe0TGWq",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "05_pytorch_going_modular_exercise_template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
